# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.extract_entities]
type = "json"
output_schema = "functions/extract_entities/output_schema.json"

[functions.extract_entities.variants.gpt_4o]
type = "chat_completion"
model = "openai::gpt-4o-2024-08-06"
system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
json_mode = "strict"

[functions.extract_entities.variants.gpt_4o_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini-2024-07-18"
system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
json_mode = "strict"

# TODO: Once you've fine-tuned your model, add it here like the commented example below

# [functions.extract_entities.variants.gpt_4o_mini_fine_tuned]
# type = "chat_completion"
# model = "openai::ft:gpt-4o-mini-2024-07-18:xxxxxxxx::xxxxxxxx"
# system_template = "functions/extract_entities/initial_prompt/system_template.minijinja"
# json_mode = "strict"

# [functions.extract_entities.variants.gpt_4o_mini_dicl]
# type = "experimental_dynamic_in_context_learning"
# embedding_model = "openai::text-embedding-3-small"
# model = "openai::gpt-4o-mini-2024-07-18"
# k = 10
# system_instructions = "functions/extract_entities/initial_prompt/system_template.minijinja"
# json_mode = "strict"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.exact_match]
type = "boolean"
level = "inference"
optimize = "max"

[metrics.jaccard_similarity]
type = "float"
level = "inference"
optimize = "max"

[metrics.valid_output]
type = "boolean"
level = "inference"
optimize = "max"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 EVALUATIONS                                │
# └────────────────────────────────────────────────────────────────────────────┘

[evaluations.eval_extract_entities]
type = "static"
function_name = "extract_entities"

[evaluations.eval_extract_entities.evaluators.match_output]
type = "llm_judge"
include = { reference_output = true }
output_type = "boolean"
optimize = "max"
cutoff = 0.9

[evaluations.eval_extract_entities.evaluators.match_output.variants.gpt_4o_mini]
type = "chat_completion"
model = "openai::gpt-4o-mini"
system_instructions = "evaluations/eval_extract_entities/match_output/system_instructions.txt"
json_mode = "strict"
